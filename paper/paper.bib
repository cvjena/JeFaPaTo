@article{soukupovaRealTimeEyeBlink2016,
  title = {Real-{{Time Eye Blink Detection}} Using {{Facial Landmarks}}},
  author = {Soukupova, Tereza},
  year = {2016},
  month = feb,
  pages = {8},
  abstract = {A real-time algorithm to detect eye blinks in a video sequence from a standard camera is proposed. Recent landmark detectors, trained on in-thewild datasets exhibit excellent robustness against a head orientation with respect to a camera, varying illumination and facial expressions. We show that the landmarks are detected precisely enough to reliably estimate the level of the eye opening. The proposed algorithm therefore estimates the landmark positions, extracts a single scalar quantity \textendash{} eye aspect ratio (EAR) \textendash{} characterizing the eye opening in each frame. Finally, an SVM classifier detects eye blinks as a pattern of EAR values in a short temporal window. The simple algorithm outperforms the state-of-the-art results on two standard datasets.},
  langid = {english},
  keywords = {Eye Blinking,Jefapato,Landmarks},
  file = {/home/buechner/OneDrive/Paper/Soukupova/Soukupova_2016_Real-Time Eye Blink Detection using Facial Landmarks.pdf}
}

@misc{lugaresiMediaPipeFrameworkBuilding2019,
  title = {{{MediaPipe}}: {{A Framework}} for {{Building Perception Pipelines}}},
  shorttitle = {{{MediaPipe}}},
  author = {Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming Guang and Lee, Juhyun and Chang, Wan-Teh and Hua, Wei and Georg, Manfred and Grundmann, Matthias},
  year = {2019},
  month = jun,
  number = {arXiv:1906.08172},
  eprint = {1906.08172},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1906.08172},
  urldate = {2023-03-20},
  abstract = {Building applications that perceive the world around them is challenging. A developer needs to (a) select and develop corresponding machine learning algorithms and models, (b) build a series of prototypes and demos, (c) balance resource consumption against the quality of the solutions, and finally (d) identify and mitigate problematic cases. The MediaPipe framework addresses all of these challenges. A developer can use MediaPipe to build prototypes by combining existing perception components, to advance them to polished cross-platform applications and measure system performance and resource consumption on target platforms. We show that these features enable a developer to focus on the algorithm or model development and use MediaPipe as an environment for iteratively improving their application with results reproducible across different devices and platforms. MediaPipe will be open-sourced at https://github.com/google/mediapipe.},
  archiveprefix = {arxiv},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/home/buechner/OneDrive/Paper/Lugaresi/Lugaresi_2019_MediaPipe - A Framework for Building Perception Pipelines.pdf;/home/buechner/OneDrive/Paper/Lugaresi/Lugaresi_2019_MediaPipe - A Framework for Building Perception Pipelines.html}
}

@article{kartynnikRealtimeFacialSurface2019a,
  title = {Real-Time {{Facial Surface Geometry}} from {{Monocular Video}} on {{Mobile GPUs}}},
  author = {Kartynnik, Yury and Ablavatski, Artsiom and Grishchenko, Ivan and Grundmann, Matthias},
  year = {2019},
  month = jul,
  journal = {ArXiv},
  volume = {abs/1907.06724},
  eprint = {1907.06724},
  primaryclass = {cs},
  doi = {10.48550/arXiv.1907.06724},
  urldate = {2022-05-15},
  abstract = {We present an end-to-end neural network-based model for inferring an approximate 3D mesh representation of a human face from single camera input for AR applications. The relatively dense mesh model of 468 vertices is well-suited for face-based AR effects. The proposed model demonstrates super-realtime inference speed on mobile GPUs (100-1000+ FPS, depending on the device and model variant) and a high prediction quality that is comparable to the variance in manual annotations of the same image.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/buechner/OneDrive/Paper/Kartynnik/Kartynnik_2019_Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs.pdf;/home/buechner/OneDrive/Paper/Kartynnik/Kartynnik_2019_Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs.html}
}

@article{virtanenSciPyFundamentalAlgorithms2020,
  title = {{{SciPy}} 1.0: Fundamental Algorithms for Scientific Computing in {{Python}}},
  shorttitle = {{{SciPy}} 1.0},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul and {SciPy 1.0 Contributors} and Vijaykumar, Aditya and Bardelli, Alessandro Pietro and Rothberg, Alex and Hilboll, Andreas and Kloeckner, Andreas and Scopatz, Anthony and Lee, Antony and Rokem, Ariel and Woods, C. Nathan and Fulton, Chad and Masson, Charles and H{\"a}ggstr{\"o}m, Christian and Fitzgerald, Clark and Nicholson, David A. and Hagen, David R. and Pasechnik, Dmitrii V. and Olivetti, Emanuele and Martin, Eric and Wieser, Eric and Silva, Fabrice and Lenders, Felix and Wilhelm, Florian and Young, G. and Price, Gavin A. and Ingold, Gert-Ludwig and Allen, Gregory E. and Lee, Gregory R. and Audren, Herv{\'e} and Probst, Irvin and Dietrich, J{\"o}rg P. and Silterra, Jacob and Webber, James T and Slavi{\v c}, Janko and Nothman, Joel and Buchner, Johannes and Kulick, Johannes and Sch{\"o}nberger, Johannes L. and {de Miranda Cardoso}, Jos{\'e} Vin{\'i}cius and Reimer, Joscha and Harrington, Joseph and Rodr{\'i}guez, Juan Luis Cano and {Nunez-Iglesias}, Juan and Kuczynski, Justin and Tritz, Kevin and Thoma, Martin and Newville, Matthew and K{\"u}mmerer, Matthias and Bolingbroke, Maximilian and Tartre, Michael and Pak, Mikhail and Smith, Nathaniel J. and Nowaczyk, Nikolai and Shebanov, Nikolay and Pavlyk, Oleksandr and Brodtkorb, Per A. and Lee, Perry and McGibbon, Robert T. and Feldbauer, Roman and Lewis, Sam and Tygier, Sam and Sievert, Scott and Vigna, Sebastiano and Peterson, Stefan and More, Surhud and Pudlik, Tadeusz and Oshima, Takuya and Pingel, Thomas J. and Robitaille, Thomas P. and Spura, Thomas and Jones, Thouis R. and Cera, Tim and Leslie, Tim and Zito, Tiziano and Krauss, Tom and Upadhyay, Utkarsh and Halchenko, Yaroslav O. and {V{\'a}zquez-Baeza}, Yoshiki},
  year = {2020},
  month = mar,
  journal = {Nature Methods},
  volume = {17},
  number = {3},
  pages = {261--272},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/s41592-019-0686-2},
  urldate = {2023-03-15},
  abstract = {Abstract             SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
  langid = {english},
  file = {/home/buechner/OneDrive/Paper/Virtanen/Virtanen_2020_SciPy 1.0 - fundamental algorithms for scientific computing in Python.pdf}
}

@misc{pyqtgraph,
  author = {Luke Campagnola},
  title = {PyQtGraph: Scientific Graphics and GUI Library for Python},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/pyqtgraph/pyqtgraph}
}

@misc{qt6,
    author = {{The Qt Componany}},
    title = {Qt},
    year = {2023},
    url = {https://www.qt.io/}
}

@misc{pyqt6,
    author = {{Riverbank Computing Limited}},
    title = {PyQt6},
    year = {2023},
    url = {https://www.riverbankcomputing.com/software/pyqt/}
}